name: Benchmark Chart Generation

# Do not run this workflow on pull request since this workflow has permission to modify contents.
on:
  push:
    branches:
      - main

permissions:
  # deployments permission to deploy GitHub pages website
  deployments: write
  # contents permission to update benchmark contents in gh-pages branch
  contents: write

env:
  CARGO_INCREMENTAL: '0'
  RUST_BACKTRACE: 1
  CLIENT_DATA_PATH: /home/runner/.local/share/safe/client
  NODE_DATA_PATH: /home/runner/.local/share/safe/node
  HEAPNODE_DATA_PATH: /home/runner/.local/share/safe/heapnode

jobs:
  benchmark:
    if: "!startsWith(github.event.head_commit.message, 'chore(release):')"
    name: Run and log benchmark criterion results on gh-pages
    # right now only ubuntu, running on multiple systems would require many pushes...\
    # perhaps this can be done with one consolidation action in the future, pulling down all results and pushing
    # once to the branch..
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y heaptrack
      - uses: actions-rs/toolchain@v1
        id: toolchain
        with:
          profile: minimal
          toolchain: stable
          override: true
          components: rustfmt, clippy

      - uses: Swatinem/rust-cache@v2
        continue-on-error: true

      - run: cargo install cargo-criterion

      - name: ubuntu install ripgrep
        run: sudo apt-get -y install ripgrep

      - name: Download 95mb file to be uploaded with the safe client
        shell: bash
        run: wget https://sn-node.s3.eu-west-2.amazonaws.com/the-test-data.zip
     
      - name: Build sn bins
        run: cargo build --release --bins --features local-discovery
        timeout-minutes: 30

      - name: Start a local network
        run: cargo run --release --bin testnet -- --interval 2000 --node-path ./target/release/safenode
        env:
          SN_LOG: "all"
        timeout-minutes: 10

      - name: Start a heaptracked node instance to compare memory usage
        run: |
          mkdir -p $HEAPNODE_DATA_PATH
          heaptrack ./target/release/safenode \
            --root-dir $HEAPNODE_DATA_PATH --log-output-dest $HEAPNODE_DATA_PATH --local &
          sleep 10
        env:
          SN_LOG: "all"

      ########################
      ### Benchmark        ###
      ########################
      - name: Bench `safe`
        shell: bash
        # Criterion outputs the actual bench results to stderr "2>&1 tee output.txt" takes stderr,
        # passes to tee which displays it in the terminal and writes to output.txt
        run: |
          cargo criterion --features=local-discovery --message-format=json 2>&1 | tee -a output.txt
          cat output.txt | rg benchmark-complete | jq -s 'map({
            name: (.id | split("/"))[-1],
            unit: "MiB/s",
            value: ((if .throughput[0].unit == "KiB/s" then (.throughput[0].per_iteration / (1024*1024*1024)) else (.throughput[0].per_iteration / (1024*1024)) end) / (.mean.estimate / 1e9))
          })' > files-benchmark.json

      - name: Remove git hooks so gh-pages git commits will work
        shell: bash
        run: rm -rf .git/hooks/pre-commit

      - name: check files-benchmark.json
        shell: bash
        run: cat files-benchmark.json
        
      # gh-pages branch is updated and pushed automatically with extracted benchmark data
      - name: Store cli files benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: "`safe files` benchmarks"
          tool: 'customBiggerIsBetter'
          output-file-path: files-benchmark.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          max-items-in-chart: 300

      - name: Start a heaptracked client instance to compare memory usage
        shell: bash
        run: heaptrack ./target/release/safe --log-output-dest data-dir files upload the-test-data.zip
        env:
          SN_LOG: "all"

      ########################
      ### Clean            ###
      ########################
      - name: Kill all nodes
        shell: bash
        timeout-minutes: 1
        if: always()
        continue-on-error: true
        run: |
          pkill safenode
          echo "$(pgrep safenode | wc -l) nodes still running"

      - name: Tar log files
        shell: bash
        continue-on-error: true
        run: |
          find $HEAPNODE_DATA_PATH -iname '*.log*' | tar -zcvf heap_node_log_files.tar.gz --files-from -
          find $NODE_DATA_PATH -iname '*.log*' | tar -zcvf nodes_log_files.tar.gz --files-from -
          find $CLIENT_DATA_PATH -iname '*.log*' | tar -zcvf client_log_files.tar.gz --files-from -
          find . -iname '*log_files.tar.gz' | tar -zcvf log_files.tar.gz --files-from -
        if: always()

      - name: Upload Logs
        uses: actions/upload-artifact@main
        with:
          name: sn_logs_benchmark_chart_generation
          path: log_files.tar.gz
        if: always()
        continue-on-error: true
      
      #########################
      ### Node Mem Analysis ###
      #########################
      - name: Check for Node heaptrack file
        shell: bash
        run: ls -la

      - name: Analyze node memory usage
        shell: bash
        run: |
          heaptrack_file=$(ls -t heaptrack.safenode.*.zst | head -1)
          heaptrack --analyze $heaptrack_file > heaptrack.safenode.txt

      - name: Upload Node Heaptrack
        uses: actions/upload-artifact@main
        with:
          name: heaptrack_safenode
          path: heaptrack.safenode.*
        continue-on-error: true

      - name: Check node memory usage
        shell: bash
        run: |
          node_mem_limit_mb="100" # mb
          memory_usage=$(rg "peak heap memory consumption" ./heaptrack.safenode.txt | awk '{
            if ($5 ~ /K/) {
              sub(/K/, "", $5);
              $5 = $5 / 1024;
            } else if ($5 ~ /G/) {
              sub(/G/, "", $5);
              $5 = $5 * 1024;
            } else if ($5 ~ /M/) {
              sub(/M/, "", $5);
              $5 = $5;
            }
            print $5;
          }' )
          echo "Memory usage: $memory_usage MB"
          if (( $(echo "$memory_usage > $node_mem_limit_mb" | bc -l) )); then
            echo "Node memory usage exceeded threshold: $memory_usage MB"
            exit 1
          fi
          # Write the node memory usage to a file
          echo '[
              {
                  "name": "Peak memory w/ `safe` benchmarks",
                  "value": '$memory_usage',
                  "unit": "MB"
              }
          ]' > node_memory_usage.json

      - name: check node_memory_usage.json
        shell: bash
        run: cat node_memory_usage.json

      - name: Upload Node Memory Usage
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: 'Node memory'
          tool: 'customSmallerIsBetter'
          output-file-path: node_memory_usage.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          max-items-in-chart: 300

      ###########################
      ### Client Mem Analysis ###
      ###########################
      - name: Check for Client heaptrack file
        shell: bash
        run: ls -la

      - name: Analyze client memory usage
        shell: bash
        run: |
          heaptrack_file=$(ls -t heaptrack.safe.*.zst | head -1)
          heaptrack --analyze $heaptrack_file > heaptrack.safe.txt

      - name: Upload Client Heaptrack
        uses: actions/upload-artifact@main
        with:
          name: heaptrack_safe
          path: heaptrack.safe.*
        continue-on-error: true

      - run: cat ./heaptrack.safe.txt 
        shell: bash

      - run: rg "peak heap memory consumption" ./heaptrack.safe.txt | awk '{print $5}' 
        shell: bash

      - name: Check client memory usage
        shell: bash
        run: |
          peak_mem_usage=$(rg "peak heap memory consumption" ./heaptrack.safe.txt | awk '{
            if ($5 ~ /K/) {
              sub(/K/, "", $5);
              $5 = $5 / 1024;
            } else if ($5 ~ /G/) {
              sub(/G/, "", $5);
              $5 = $5 * 1024;
            } else if ($5 ~ /M/) {
              sub(/M/, "", $5);
              $5 = $5;
            }
            print $5;
          }')
          client_peak_mem_limit_mb="2000" # mb
          echo "Peak memory usage: $peak_mem_usage MB"
          if (( $(echo "$peak_mem_usage > $client_peak_mem_limit_mb" | bc -l) )); then
            echo "Client peak memory usage exceeded threshold: $client_peak_mem_limit_mb MB"
            exit 1
          fi

          mem_reads=($(rg "\"memory_used_mb\":\d+" $CLIENT_DATA_PATH/logs/safenode.* \
            -o --no-line-number --no-filename | rg "\d+" -o))
          total_mem=$(ls heaptrack.safe.txt | wc -l)
          echo "Total memory initial value is: $total_mem"
          for mem in "${mem_reads[@]}"; do
            total_mem=$((total_mem+$(($mem))))
          done

          client_avg_mem_limit_mb="700" # mb
          num_of_times=$(rg "\"memory_used_mb\"" $CLIENT_DATA_PATH/logs/safenode.* \
            -c --stats | rg "(\d+) matches" | rg "\d+" -o)
          echo "num_of_times: $num_of_times"
          echo "Total memory is: $total_mem"
          average_mem=$(($total_mem/$(($num_of_times))))
          echo "Average memory is: $average_mem"
          if (( $(echo "$average_mem > $client_avg_mem_limit_mb" | bc -l) )); then
            echo "Client average memory usage exceeded threshold: $client_avg_mem_limit_mb MB"
            exit 1
          fi
          # Write the client memory usage to a file
          echo '[
              {
                  "name": "Peak memory usage w/ upload",
                  "value": '$peak_mem_usage',
                  "unit": "MB"
              },
              {
                  "name": "Average memory usage w/ upload",
                  "value": '$average_mem',
                  "unit": "MB"
              }
          ]' > client_memory_usage.json

      - name: check client_memory_usage.json
        shell: bash
        run: cat client_memory_usage.json

      - name: Upload Client Memory Usage
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: 'Client memory'
          tool: 'customSmallerIsBetter'
          output-file-path: client_memory_usage.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          max-items-in-chart: 300
