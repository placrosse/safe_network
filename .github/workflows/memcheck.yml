name: Memory Check

on:
  # tests must run for a PR to be valid and pass merge queue muster
  # on main, we want to know that all commits are passing at a glance, any deviation should help bisecting errors
  # the merge run checks should show on master and enable this clear test/passing history
  merge_group:
    branches: [main]
  pull_request:
    branches: ["*"]

env:
  CLIENT_DATA_PATH: /home/runner/.local/share/safe/client
  NODE_DATA_PATH: /home/runner/.local/share/safe/node
  HEAPNODE_DATA_PATH: /home/runner/.local/share/safe/heapnode

jobs:
  memory-check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y heaptrack
  
      - name: Install Rust
        id: toolchain
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          toolchain: stable
          override: true

      - uses: Swatinem/rust-cache@v2
        continue-on-error: true

      - name: install ripgrep
        shell: bash
        run: sudo apt-get install -y ripgrep

      - name: Build sn bins
        run: cargo build --release --bins 
        timeout-minutes: 30

      - name: Build churn tests 
        run: cargo test --release -p sn_node --no-run
        timeout-minutes: 30

      - name: Start a heaptracked node instance to compare memory usage
        run: |
          mkdir -p $HEAPNODE_DATA_PATH
          heaptrack ./target/release/safenode \
            --root-dir $HEAPNODE_DATA_PATH --log-output-dest $HEAPNODE_DATA_PATH --local &
          sleep 10
        env:
          SN_LOG: "all"

      - name: Set SAFE_PEERS
        run: |
          safe_peers=$(rg "listening on \".+\"" $HEAPNODE_DATA_PATH -u | \
            rg '/ip4.*$' -m1 -o | rg '"' -r '')
          echo "SAFE_PEERS=$safe_peers" >> $GITHUB_ENV

      - name: Check SAFE_PEERS
        shell: bash
        run: echo "Contact peer is set to $SAFE_PEERS"

      - name: Start a local network
        run: cargo run --release --bin testnet -- --interval 2000 --node-path ./target/release/safenode
        env:
          SN_LOG: "all"
        timeout-minutes: 10

      # The resources file we upload may change, and with it mem consumption.
      # Be aware!
      - name: Start a client to upload files
        run: |
          ls -l ./target/release
          cargo run --bin safe --release -- files upload -- "./target/release/faucet"
          cargo run --bin safe --release -- files upload -- "./target/release/safe"
          cargo run --bin safe --release -- files upload -- "./target/release/safenode"
          cargo run --bin safe --release -- files upload -- "./target/release/testnet"
        id: client-file-upload
        env:
          SN_LOG: "all"
        timeout-minutes: 10

      - name: Chunks data integrity during nodes churn
        run: cargo test --release -p sn_node --test data_with_churn -- --nocapture 
        env:
          TEST_DURATION_MINS: 15
          SN_LOG: "all"
        timeout-minutes: 20

      - name: Verify restart of nodes using rg
        shell: bash
        timeout-minutes: 1
        # get the counts, then the specific line, and then the digit count only
        # then check we have an expected level of restarts
        # TODO: make this use an env var, or relate to testnet size
        run : |
          restart_count=$(rg "Node is restarting in" $NODE_DATA_PATH -c --stats | \
            rg "(\d+) matches" | rg "\d+" -o)
          echo "Restart $restart_count nodes"
          detected_dead_peer=$(rg "Detected dead peer" $NODE_DATA_PATH -c --stats | \
            rg "(\d+) matches" | rg "\d+" -o)
          echo "Detected dead peer $detected_dead_peer times"
          if [ $detected_dead_peer -lt $restart_count ]; then
            echo "Detected dead peer times of: $detected_dead_peer is less than the restart count of: $restart_count"
            exit 1
          fi
          node_count=$(ls $NODE_DATA_PATH | wc -l)
          echo "Node dir count is $node_count"
        # TODO: reenable this once the testnet dir creation is tidied up to avoid a large count here
        # if [ $restart_count -lt $node_count ]; then
        #   echo "Restart count of: $restart_count is less than the node count of: $node_count"
        #   exit 1
        # fi
          
      - name: Verify data replication using rg
        shell: bash
        timeout-minutes: 1
        # get the counts, then the specific line, and then the digit count only
        # then check we have an expected level of replication
        # TODO: make this use an env var, or relate to testnet size
        # As the heap_node using separate folder for logging, 
        # hence the folder input to rg needs to cover that as well.
        run : |
          sending_list_count=$(rg "Sending a replication list" $NODE_DATA_PATH -c --stats | \
            rg "(\d+) matches" | rg "\d+" -o)
          echo "Sent $sending_list_count replication lists"
          received_list_count=$(rg "Replicate list received from" $NODE_DATA_PATH -c --stats | \
            rg "(\d+) matches" | rg "\d+" -o)
          echo "Received $received_list_count replication lists"
          fetching_attempt_count=$(rg "Fetching replication" $NODE_DATA_PATH -c --stats | \
            rg "(\d+) matches" | rg "\d+" -o)
          echo "Carried out $fetching_attempt_count fetching attempts"
          replication_attempt_count=$(rg "Replicating chunk" $NODE_DATA_PATH -c --stats | \
            rg "(\d+) matches" | rg "\d+" -o)
          echo "Sent $replication_attempt_count chunk copies"
          replication_count=$(rg "Chunk received for replication" $NODE_DATA_PATH -c --stats | \
            rg "(\d+) matches" | rg "\d+" -o)
          echo "Received $replication_count chunk copies"
          node_count=$(ls $NODE_DATA_PATH | wc -l)
          if [ $replication_count -lt $node_count ]; then
            echo "Replication count of: $replication_count is less than the node count of: $node_count"
            exit 1
          fi
        if: always()

      - name: Start a client to download files
        run: |
          cargo run --bin safe --release -- files download
          ls -l $CLIENT_DATA_PATH/downloaded_files
          downloaded_files=$(ls $CLIENT_DATA_PATH/downloaded_files | wc -l)
          if [ $downloaded_files -lt 4 ]; then
            echo "Only downloaded $downloaded_files files, less than the 4 files uploaded"
            exit 1
          fi
        env:
          RUST_LOG: "safenode,safe=trace"
        timeout-minutes: 10

      - name: Check nodes running
        shell: bash
        timeout-minutes: 1
        continue-on-error: true
        run: pgrep safenode | wc -l
        if: always()

      - name: Kill all nodes
        shell: bash
        timeout-minutes: 1
        continue-on-error: true
        run: |
          killall safenode
          echo "$(pgrep safenode | wc -l) nodes still running"
        if: always()

      - name: Check for heaptrack file
        run: ls -la

      - name: Analyze memory usage
        shell: bash
        run: |
          heaptrack_file=$(ls -t heaptrack.safenode.*.zst | head -1)
          heaptrack --analyze $heaptrack_file > heaptrack.safenode.txt
        if: always()
     
      - name: Check memory usage
        shell: bash
        # The resources file and churning chunk_size we upload may change, and with it mem consumption.
        # This is set to a value high enough to allow for some variation depending on 
        # resources and node locatin in the network, but hopefully low enough to catch 
        # any wild memory issues 
        # Any changes to this value should be carefully considered and tested!
        # As the heap_node also acting as a bootstrap access point for churning nodes and client,
        # The memory usage here will be sinificantly higher here than in the benchmark test,
        # where the heap_node only act as a normal network member.
        run: |
          mem_limit_mb="160" # mb
          memory_usage=$(rg "peak heap memory consumption" ./heaptrack.safenode.txt | awk '{
            if ($5 ~ /K/) {
              sub(/K/, "", $5);
              $5 = $5 / 1024;
            } else if ($5 ~ /G/) {
              sub(/G/, "", $5);
              $5 = $5 * 1024;
            }
            else if ($5 ~ /M/) {
              sub(/M/, "", $5);
              $5 = $5;
            }
            print $5;
          }')
          echo "Memory usage: $memory_usage MB"
          if (( $(echo "$memory_usage > $mem_limit_mb" | bc -l) )); then
            echo "Memory usage exceeded threshold: $memory_usage MB"
            exit 1
          fi
        if: always()

      - name: Tar log files
        shell: bash
        continue-on-error: true
        run: |
          find $HEAPNODE_DATA_PATH -iname '*.log*' | tar -zcvf heap_node_log_files.tar.gz --files-from -
          find $NODE_DATA_PATH -iname '*.log*' | tar -zcvf nodes_log_files.tar.gz --files-from -
          find $CLIENT_DATA_PATH -iname '*.log*' | tar -zcvf client_log_files.tar.gz --files-from -
          find . -iname '*log_files.tar.gz' | tar -zcvf log_files.tar.gz --files-from -
        if: failure()

      - name: Upload Heaptrack
        uses: actions/upload-artifact@main
        with:
          name: heaptrack_safenode
          path: heaptrack.safenode.*
        continue-on-error: true
        if: always()

      - name: Upload Node Logs
        uses: actions/upload-artifact@main
        with:
          name: sn_node_logs_memcheck
          path: log_files.tar.gz
        if: failure()
        continue-on-error: true
